# dags/weather_monthly_dag.py

from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from airflow.models import Variable
from datetime import datetime, timedelta
from datetime import timezone
import logging
import requests
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from meteostat import Daily
from telegram import Bot
import os
from io import BytesIO

# === ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð¸ ÐºÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ ===
TELEGRAM_BOT_TOKEN = Variable.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = Variable.get("TELEGRAM_CHAT_ID")

CITIES = {
    'Moscow': '27611',
    'Saint Petersburg': '27612',
    'Adler': '37171'
}

HDFS_NAMENODE = "http://namenode:50070/webhdfs/v1"
HDFS_USER = "airflow"

LOCAL_TEMP_DIR = "/tmp/hdfs_data/"
os.makedirs(LOCAL_TEMP_DIR, exist_ok=True)

RAW_HDFS_PATH = "/raw/weather/{{ ds }}/raw_weather.json"
HDFS_LATEST_PATH = "/raw/weather/latest/raw_weather.json"
PROCESSED_HDFS_PATH = "/processed/weather/{{ ds }}/temperature.png"


# === Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² HDFS ===

def fetch_weather_data(**kwargs):
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¾ Ð¿Ð¾Ð³Ð¾Ð´Ðµ Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð¼ÐµÑÑÑ† Ð¸ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ DataFrame"""
    today = datetime.today()
    first_day = datetime(today.year, today.month - 1, 1)

    all_data = []

    for city, station_id in CITIES.items():
        data = Daily(station_id, start=first_day, end=today).fetch().reset_index()
        if data.empty:
            logging.warning(f"ÐÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ {city}")
            continue

        data['city'] = city
        all_data.append(data)

    if not all_data:
        raise Exception("âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð½Ð¸ Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ð°")

    df = pd.concat(all_data, ignore_index=True)
    df['time'] = df['time'].astype(str)  # Ð§Ñ‚Ð¾Ð±Ñ‹ Ð¸Ð·Ð±ÐµÐ¶Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼ Ð¿Ñ€Ð¸ ÑÐµÑ€Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    return df.to_json()


def save_to_hdfs(df_json, hdfs_path=None):
    """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ JSON Ð² HDFS Ñ‡ÐµÑ€ÐµÐ· WebHDFS REST API"""
    hdfs_path = hdfs_path or HDFS_RAW_PATH

    parent_dir = os.path.dirname(hdfs_path)

    mkdirs_url = f"{HDFS_NAMENODE}{parent_dir}?op=MKDIRS&user.name={HDFS_USER}"
    response = requests.put(mkdirs_url)

    if response.status_code not in (200, 201):
        logging.warning(f"âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ {parent_dir}: {response.text}")

    create_url = f"{HDFS_NAMENODE}{hdfs_path}?op=CREATE&user={HDFS_USER}&overwrite=True"

    response = requests.put(create_url, allow_redirects=False)
    if response.status_code != 307:
        raise Exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Ð² HDFS: {response.text}")

    datanode_url = response.headers['Location']
    response = requests.put(datanode_url, data=df_json, headers={'Content-Type': 'application/json'})
    if response.status_code != 201:
        raise Exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² HDFS: {response.text}")

    logging.info(f"âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ñ‹ Ð² HDFS: {hdfs_path}")


def read_from_hdfs(hdfs_path=None):
    """Ð§Ð¸Ñ‚Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· HDFS Ñ‡ÐµÑ€ÐµÐ· WebHDFS REST API"""

    open_url = f"{HDFS_NAMENODE}{hdfs_path}?op=OPEN&user={HDFS_USER}"

    response = requests.get(open_url, allow_redirects=False)
    if response.status_code != 307:
        raise Exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ñ‚ÐºÑ€Ñ‹Ñ‚Ð¸Ñ Ñ„Ð°Ð¹Ð»Ð° Ð² HDFS: {response.text}")

    datanode_url = response.headers['Location']
    response = requests.get(datanode_url)

    if response.status_code != 200:
        raise Exception(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ñ‡Ñ‚ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸Ð· HDFS: {response.text}")

    # Ð˜ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð½Ñ‹Ð¹ Ð²Ñ‹Ð·Ð¾Ð² pandas
    try:
        df = pd.read_json(BytesIO(response.content))
        return df
    except ValueError as e:
        logging.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ñ‚ÑŒ JSON: {e}")
        raise
    


def generate_plot(df, output_path="/tmp/temperature_plot.png"):
    """Ð¡Ñ‚Ñ€Ð¾Ð¸Ñ‚ Ð³Ñ€Ð°Ñ„Ð¸Ðº Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ñ‹ Ð¿Ð¾ Ð´Ð½ÑÐ¼ Ð´Ð»Ñ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ Ð³Ð¾Ñ€Ð¾Ð´Ð°"""
    plt.figure(figsize=(14, 7))
    sns.lineplot(data=df, x="time", y="tavg", hue="city", marker="o")
    plt.xticks(rotation=45)
    plt.title("Ð¡Ñ€ÐµÐ´Ð½ÑÑ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° (Â°C) Ð·Ð° Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ Ð¼ÐµÑÑÑ†")
    plt.tight_layout()
    plt.savefig(output_path)
    plt.close()

    return output_path


# === Ð—Ð°Ð´Ð°Ñ‡Ð¸ DAG'Ð° ===
def fetch_and_save_to_hdfs(**kwargs):
    """Ð—Ð°Ð¿Ñ€Ð°ÑˆÐ¸Ð²Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ Ð² HDFS"""
    df_json = fetch_weather_data(**kwargs)
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð² HDFS
    
    hdfs_path = RAW_HDFS_PATH.replace("{{ ds }}", kwargs['ds'])
    latest_path = "/raw/weather/latest/raw_weather.json"

    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ð¾ Ð´Ð°Ñ‚Ðµ
    save_to_hdfs(df_json, hdfs_path)

    # Ð”ÑƒÐ±Ð»Ð¸Ñ€ÑƒÐµÐ¼ Ð² /latest/ Ð´Ð»Ñ Ð±Ð¾Ñ‚Ð°
    save_to_hdfs(df_json, "/raw/weather/latest/raw_weather.json")
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿ÑƒÑ‚ÑŒ Ð² XCom
    ti = kwargs['ti']
    ti.xcom_push(key='hdfs_path', value=hdfs_path)


def build_and_send_plot(**kwargs):
    """Ð§Ð¸Ñ‚Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· HDFS, ÑÑ‚Ñ€Ð¾Ð¸Ñ‚ Ð³Ñ€Ð°Ñ„Ð¸Ðº Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð² Telegram"""
    ti = kwargs['ti']
    hdfs_path = ti.xcom_pull(task_ids='fetch_and_save_to_hdfs', key='hdfs_path')
    
    # Ð§Ñ‚ÐµÐ½Ð¸Ðµ Ð¸Ð· HDFS
    df = read_from_hdfs(hdfs_path)

    # ÐŸÐ¾ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ°
    plot_path = "/tmp/temperature_plot.png"
    plot_path = generate_plot(df, plot_path)

    # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ñ‡ÐµÑ€ÐµÐ· Telegram
    bot = Bot(token=TELEGRAM_BOT_TOKEN)
    with open(plot_path, 'rb') as photo:
        bot.send_photo(chat_id=TELEGRAM_CHAT_ID, photo=photo, caption="ðŸ“Š Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð·Ð° Ð¿Ñ€Ð¾ÑˆÐ»Ñ‹Ð¹ Ð¼ÐµÑÑÑ†")


# === DAG ===
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'email_on_failure': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

with DAG(
    dag_id='weather_monthly_pipeline',
    default_args=default_args,
    description='A pipeline to fetch, store and visualize weather data via WebHDFS REST API',
    schedule_interval="@monthly",
    start_date=datetime(2024, 1, 1),
    catchup=False,
) as dag:

    fetch_task = PythonOperator(
        task_id='fetch_and_save_to_hdfs',
        python_callable=fetch_and_save_to_hdfs,
        provide_context=True,
    )

    plot_task = PythonOperator(
        task_id='generate_plot',
        python_callable=build_and_send_plot,
        provide_context=True,
    )

    # Ð¡Ð²ÑÐ·ÑŒ Ð·Ð°Ð´Ð°Ñ‡
    fetch_task >> plot_task